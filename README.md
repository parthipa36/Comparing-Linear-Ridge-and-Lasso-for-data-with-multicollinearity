# Comparing-Linear-Ridge-and-Lasso-for-data-with-multicollinearity
A Comparative study on Linear, Ridge and Lasso Regression models for data containing multi-collinear variables

##--This paper is written during my full time course in PGP Data Science, Praxis Buiness School. ---##

Abstract:
Regression analysis is one of the popular statistical method used in almost all industries and used to determine the strength of the relationship between one dependent variable (usually denoted by Y) and a series of other changing variables (known as independent variables). Many techniques are there for regression analysis and one of the familiar method is linear regression. 

In Regression, many errors may occur such as Non linearity of the response and predictor relationships, correlation of error terms, Non constant variance of error terms, outliers, high leverage points and multicollinearity. Among these, Multicollinearity among the variables is one of the major problem in regression analysis. We can reduce that multicollinearity by using regularized regressions such as Ridge regression and Lasso regression.

This study is concentrating more about comparison on linear, ridge and lasso regression models for data containing multicollinear variables by taking a use case. The dataset is solved using all the three methods individually. The result will explain about the advantages and disadvantages of each of the models that exists among each other. It also explains about how these models handle the errors of the test data due to the presence of multicollinearity among the variables. 

The conclusion can be drawn that this comparative study of these three models will result in which model handles multicollinearity in easier manner than the other two methods. All the required calculations and graphical displays are performed using the R software for statistical computing.


##---Please find the paper as well as the code part in this repository---#
